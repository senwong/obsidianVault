

## hyper-parameters
超参数，指训练过程中，人工指定的参数，不是模型训练的参数。对应model-parameters(模型参数)，是在训练过程中优化的参数。
超参数一般包括
- Learning-rate(学习率)，
- 正则化参数（Regularization Parameters
- 树模型的深度和叶子节点数
- 支持向量机中的C和核函数参数
- 神经网络中的隐藏层节点数、层数和激活函数
- K近邻中的K值
获取超参数的方法：网格搜索（Grid Search）、随机搜索（Random Search）
相关知识点：超参数调优。


---

## 1 Cycle Policy

学习率的变化
传统的方法：
1. 在训练模型前固定一个学习率，在训练的过程中按照一定的策略固定更新学习率（Time-Based Decay, Step Decay, Exponential Decay, etc）
2. 在训练模型前固定一个学习率，在训练的过程中自适应更新学习率Adagrad, Adadelta, RMSprop, Adam, etc， 参考：http://arxiv.org/abs/1609.04747

Cyclical Learning Rate：
指定学习率的最大值和最小值，1个cycle包含一次lr增加和减少，
![clr_img](https://iconof.com/static/5077dd3668a084c1059abce622ab4310/07975/clr.png)

